{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {}\n",
    "parameters['seq_length'] = 5\n",
    "parameters['n_input'] = 3\n",
    "parameters['n_output'] = 3\n",
    "parameters['n_hidden'] = 4\n",
    "parameters['init_stdev'] = 0.1\n",
    "parameters['learning_rate'] = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some auxilar functions\n",
    "def _seq_length(sequence):\n",
    "    used = tf.sign(tf.reduce_max(tf.abs(sequence), reduction_indices=2))\n",
    "    length = tf.reduce_sum(used, reduction_indices=1)\n",
    "    length = tf.cast(length, tf.int32)\n",
    "    return length\n",
    "\n",
    "def _last_relevant(output, length):\n",
    "    batch_size = tf.shape(output)[0]\n",
    "    max_length = tf.shape(output)[1]\n",
    "    out_size = int(output.get_shape()[2])\n",
    "    index = tf.range(0, batch_size) * max_length + (length - 1)\n",
    "    flat = tf.reshape(output, [-1, out_size])\n",
    "    relevant = tf.gather(flat, index)\n",
    "\n",
    "    return relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-8e1884f6a660>:39: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define placeholders\n",
    "x = tf.placeholder(\"float\", [None, parameters['seq_length'], parameters['n_input']], name='x')\n",
    "y = tf.placeholder(\"float\", [None, parameters['n_output']], name='y')\n",
    "\n",
    "# Define weights and bias - For now we will try with attention to hidden state \n",
    "# \n",
    "weights = {\n",
    "    'alphas': tf.Variable(tf.random_normal([parameters['n_hidden'], 1], stddev=parameters['init_stdev'])),\n",
    "    'out': tf.Variable(tf.random_normal([parameters['n_hidden'], parameters['n_output']], \n",
    "                                        stddev=parameters['init_stdev']), name='w_out')\n",
    "        }\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([parameters['n_output']]), name='b_out'),\n",
    "    'alphas': tf.Variable(tf.random_normal([1]), name='b_alphas')\n",
    "}\n",
    "\n",
    "# Define RNN\n",
    "rnn_cell = tf.contrib.rnn.LSTMCell(parameters['n_hidden'])\n",
    "outputs, states = tf.nn.dynamic_rnn(\n",
    "    rnn_cell,\n",
    "    x,\n",
    "    dtype=tf.float32,\n",
    "    sequence_length=_seq_length(x)\n",
    ")\n",
    "\n",
    "# Define attention weihts\n",
    "outputs_reshaped = tf.reshape(outputs, [-1, int(outputs.get_shape()[2])])\n",
    "ejs = tf.matmul(outputs_reshaped, weights['alphas']) + biases['alphas'] \n",
    "ejs_reshaped = tf.reshape(ejs, [-1, int(outputs.get_shape()[1])])\n",
    "alphas = tf.nn.softmax(ejs_reshaped, name='attention_weights') \n",
    "reshaped_alphas = tf.reshape(alphas, [-1, 1])\n",
    "# Define context\n",
    "context = reshaped_alphas * outputs_reshaped\n",
    "context_reshaped = tf.reshape(context, [-1, parameters['seq_length'], int(context.get_shape()[1])])\n",
    "context_reduced = tf.reduce_sum(context_reshaped, axis= 1)\n",
    "# Define logits and loss\n",
    "logits = tf.matmul(context_reduced, weights['out']) + biases['out']\n",
    "pred_prob = tf.nn.softmax(logits, name=\"predictions\")\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "\n",
    "#Define optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=parameters['learning_rate']).minimize(loss)\n",
    "\n",
    "# Initialization\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample 1a\n",
    "x1a = np.array([\n",
    "        [1,0,0],\n",
    "        [0,1,0],\n",
    "        [0,0,1],\n",
    "        [1,0,0],\n",
    "        [1,0,0]\n",
    "    ])\n",
    "y1a = np.array([1,0,0])\n",
    "# Sample 1b\n",
    "x1b = np.array([\n",
    "        [1,0,0],\n",
    "        [0,1,0],\n",
    "        [0,0,1],\n",
    "        [0,1,0],\n",
    "        [0,1,0]\n",
    "    ])\n",
    "y1b = np.array([1,0,0])\n",
    "# Sample 1c\n",
    "x1c = np.array([\n",
    "        [1,0,0],\n",
    "        [0,1,0],\n",
    "        [0,0,1],\n",
    "        [0,0,1],\n",
    "        [0,0,1]\n",
    "    ])\n",
    "y1c = np.array([1,0,0])\n",
    "# Sample 2a\n",
    "x2a = np.array([\n",
    "        [0,0,1],\n",
    "        [0,0,1],\n",
    "        [0,0,1],\n",
    "        [0,0,1],\n",
    "        [0,0,1]\n",
    "    ])\n",
    "y2a = np.array([0,1,0])\n",
    "# Sample 2b\n",
    "x2b = np.array([\n",
    "        [0,0,1],\n",
    "        [0,0,1],\n",
    "        [0,1,0],\n",
    "        [0,1,0],\n",
    "        [0,1,0]\n",
    "    ])\n",
    "y2b = np.array([0,1,0])\n",
    "# Sample 2a\n",
    "x2c = np.array([\n",
    "        [0,0,1],\n",
    "        [0,0,1],\n",
    "        [1,0,0],\n",
    "        [1,0,0],\n",
    "        [1,0,0]\n",
    "    ])\n",
    "y2c = np.array([0,1,0])\n",
    "# Sample 3a\n",
    "x3a = np.array([\n",
    "        [0,0,1],\n",
    "        [0,1,0],\n",
    "        [0,0,1],\n",
    "        [0,1,0],\n",
    "        [1,0,0]\n",
    "    ])\n",
    "y3a = np.array([0,0,1])\n",
    "# Sample 3b\n",
    "x3b = np.array([\n",
    "        [0,0,1],\n",
    "        [0,1,0],\n",
    "        [0,0,1],\n",
    "        [0,1,0],\n",
    "        [0,1,0]\n",
    "    ])\n",
    "y3b = np.array([0,0,1])\n",
    "# Sample 3c\n",
    "x3c = np.array([\n",
    "        [0,0,1],\n",
    "        [0,1,0],\n",
    "        [0,0,1],\n",
    "        [0,1,0],\n",
    "        [0,0,1]\n",
    "    ])\n",
    "y3c = np.array([0,0,1])\n",
    "\n",
    "# Add 2 samples of each to list\n",
    "X = [x1a, np.copy(x1a), x1b, np.copy(x1b), x1c, np.copy(x1c), x2a, np.copy(x2a), x2b, np.copy(x2b), x3a, np.copy(x3a), x3b, np.copy(x3b), x3c, np.copy(x3c)]\n",
    "Y = [y1a, np.copy(y1a), y1b, np.copy(y1b), y1c, np.copy(y1c), y2a, np.copy(y2a), y2b, np.copy(y2b), y3a, np.copy(y3a), y3b, np.copy(y3a), y3c, np.copy(y3c)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Loss= 1.0990\n",
      "Step 20, Loss= 0.9693\n",
      "Step 40, Loss= 0.5747\n",
      "Step 60, Loss= 0.3588\n",
      "Step 80, Loss= 0.2425\n",
      "Step 100, Loss= 0.1645\n",
      "Step 120, Loss= 0.1107\n",
      "Step 140, Loss= 0.0746\n",
      "Step 160, Loss= 0.0522\n",
      "Step 180, Loss= 0.0386\n",
      "Step 200, Loss= 0.0301\n",
      "Step 220, Loss= 0.0244\n",
      "Step 240, Loss= 0.0203\n",
      "Step 260, Loss= 0.0174\n",
      "Step 280, Loss= 0.0151\n",
      "Optimization Finished!\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b'models/attentionRNN/SavedModelBuilder/saved_model.pb'\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, 300):\n",
    "        batch_x = np.array(X)\n",
    "        batch_y = np.array(Y)\n",
    "        # Run optimization op (backprop)\n",
    "        a = sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        if step % 20 == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            train_loss = sess.run(loss, feed_dict={x: batch_x, y: batch_y})\n",
    "            print(\"Step \" + str(step) + \", Loss= {:.4f}\".format(train_loss))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "   \n",
    "    # Once trained - Get attention weights for the training samples\n",
    "    attention_weights = sess.run(alphas, feed_dict={x: batch_x})\n",
    "\n",
    "    # Saved Model Builder \n",
    "    export_path = \"models/attentionRNN/SavedModelBuilder/\"\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "    builder.add_meta_graph_and_variables(\n",
    "          sess, [tf.saved_model.tag_constants.SERVING])\n",
    "    builder.save()\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check some attention weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17468816,  0.1399889 ,  0.23449016,  0.23826963,  0.21256314],\n",
       "       [ 0.17468816,  0.1399889 ,  0.23449016,  0.23826963,  0.21256314],\n",
       "       [ 0.18295713,  0.14661536,  0.2455899 ,  0.21695247,  0.20788521],\n",
       "       [ 0.18295713,  0.14661536,  0.2455899 ,  0.21695247,  0.20788521],\n",
       "       [ 0.17491445,  0.14017023,  0.23479392,  0.23057485,  0.21954654],\n",
       "       [ 0.17491445,  0.14017023,  0.23479392,  0.23057485,  0.21954654],\n",
       "       [ 0.00067953,  0.05624923,  0.26769829,  0.34160104,  0.33377188],\n",
       "       [ 0.00067953,  0.05624923,  0.26769829,  0.34160104,  0.33377188],\n",
       "       [ 0.00306775,  0.25393713,  0.59615821,  0.11737238,  0.02946457],\n",
       "       [ 0.00306775,  0.25393713,  0.59615821,  0.11737238,  0.02946457],\n",
       "       [ 0.05021417,  0.13395223,  0.25083759,  0.29002962,  0.27496645],\n",
       "       [ 0.05021417,  0.13395223,  0.25083759,  0.29002962,  0.27496645],\n",
       "       [ 0.04867735,  0.12985256,  0.24316061,  0.28115314,  0.29715633],\n",
       "       [ 0.04867735,  0.12985256,  0.24316061,  0.28115314,  0.29715633],\n",
       "       [ 0.04815224,  0.12845179,  0.24053751,  0.27812022,  0.30473822],\n",
       "       [ 0.04815224,  0.12845179,  0.24053751,  0.27812022,  0.30473822]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
